{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install import_ipynb"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IUfvyGv5-8y3","executionInfo":{"status":"ok","timestamp":1684071667683,"user_tz":-180,"elapsed":10561,"user":{"displayName":"Ayşın Tümay","userId":"06380358222498876955"}},"outputId":"f63db305-2b37-42c7-fa36-b2935bdb133e"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting import_ipynb\n","  Downloading import_ipynb-0.1.4-py3-none-any.whl (4.1 kB)\n","Requirement already satisfied: IPython in /usr/local/lib/python3.10/dist-packages (from import_ipynb) (7.34.0)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from import_ipynb) (5.8.0)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from IPython->import_ipynb) (67.7.2)\n","Collecting jedi>=0.16 (from IPython->import_ipynb)\n","  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from IPython->import_ipynb) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from IPython->import_ipynb) (0.7.5)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from IPython->import_ipynb) (5.7.1)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from IPython->import_ipynb) (3.0.38)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from IPython->import_ipynb) (2.14.0)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from IPython->import_ipynb) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from IPython->import_ipynb) (0.1.6)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from IPython->import_ipynb) (4.8.0)\n","Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->import_ipynb) (2.16.3)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->import_ipynb) (4.3.3)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.10/dist-packages (from nbformat->import_ipynb) (5.3.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->IPython->import_ipynb) (0.8.3)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (23.1.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (0.19.3)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->IPython->import_ipynb) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython->import_ipynb) (0.2.6)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core->nbformat->import_ipynb) (3.3.0)\n","Installing collected packages: jedi, import_ipynb\n","Successfully installed import_ipynb-0.1.4 jedi-0.18.2\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xmo8wbsm-cVY","executionInfo":{"status":"ok","timestamp":1684071695686,"user_tz":-180,"elapsed":28007,"user":{"displayName":"Ayşın Tümay","userId":"06380358222498876955"}},"outputId":"c0df0338-fee1-4581-f726-7ef5343baf33"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!cp /content/drive/MyDrive/EEE\\ 485\\ Project/Code/Sunum\\ kodu/metrics.ipynb /content"],"metadata":{"id":"5-obOTer-bCO","executionInfo":{"status":"ok","timestamp":1684071771925,"user_tz":-180,"elapsed":1033,"user":{"displayName":"Ayşın Tümay","userId":"06380358222498876955"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","from sklearn.preprocessing import MinMaxScaler,StandardScaler\n","from sklearn.metrics import mean_squared_error,r2_score\n","import matplotlib.pyplot as plt\n","import import_ipynb\n","import itertools\n","from metrics import (r2,\n","                    mse,\n","                    mae,\n","                    mape,\n",")"],"metadata":{"id":"dxWy8WLv7dsU","executionInfo":{"status":"ok","timestamp":1684071783786,"user_tz":-180,"elapsed":8043,"user":{"displayName":"Ayşın Tümay","userId":"06380358222498876955"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8621b5c4-0310-4c7d-cee0-ae4c8920747d"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["importing Jupyter notebook from metrics.ipynb\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: import_ipynb in /usr/local/lib/python3.10/dist-packages (0.1.4)\n","Requirement already satisfied: IPython in /usr/local/lib/python3.10/dist-packages (from import_ipynb) (7.34.0)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from import_ipynb) (5.8.0)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from IPython->import_ipynb) (67.7.2)\n","Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from IPython->import_ipynb) (0.18.2)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from IPython->import_ipynb) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from IPython->import_ipynb) (0.7.5)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from IPython->import_ipynb) (5.7.1)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from IPython->import_ipynb) (3.0.38)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from IPython->import_ipynb) (2.14.0)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from IPython->import_ipynb) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from IPython->import_ipynb) (0.1.6)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from IPython->import_ipynb) (4.8.0)\n","Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->import_ipynb) (2.16.3)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->import_ipynb) (4.3.3)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.10/dist-packages (from nbformat->import_ipynb) (5.3.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->IPython->import_ipynb) (0.8.3)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (23.1.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (0.19.3)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->IPython->import_ipynb) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython->import_ipynb) (0.2.6)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core->nbformat->import_ipynb) (3.3.0)\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","cp: cannot stat '/content/drive/MyDrive/EEE 485 Project/Code/main.ipynb': No such file or directory\n"]}]},{"cell_type":"code","source":["\n","class Scaling():\n","\n","  \"\"\"\n","  Applies Standard Scaler and Min Max Scaler.\n","  ;minmax: when True runs Min Max Scaler\n","  \"\"\"\n","  def __init__(self):\n","    self.__means = {}\n","    self.__vars  = {}\n","    self.__mins = {}\n","    self.__maxs = {}\n","  def fit(self, dffff, minmax = None):\n","      if minmax:\n","        for column in dffff.columns:\n","          min_one =(dffff[column]).min(axis=0)\n","          max_one = (dffff[column]).max(axis=0)\n","          final_col_train = (dffff[column] - min_one)/(max_one-min_one)\n","          dffff[column] = final_col_train\n","          self.__mins[column] = min_one\n","          self.__maxs[column] = max_one\n","      else:\n","        for column in dffff.columns:\n","          mean_one = np.mean(np.array(dffff[column]), 0)\n","          final_col_train = (dffff[column] - mean_one)\n","          stdd = np.std(final_col_train, ddof=0)\n","          final_col_train =  final_col_train/stdd\n","\n","          dffff[column] = final_col_train\n","\n","          self.__means[column] = mean_one\n","          self.__vars[column] = stdd\n","      return dffff\n","\n","  def transform(self, df, minmax = None):\n","      if minmax:\n","        for column in df.columns:\n","          final_col_test = ( df[column].values - self.__mins[column])/(self.__maxs[column] - self.__mins[column]) \n","          df[column] = final_col_test\n","      else:\n","        for column in df.columns:\n","          final_col_test = ( df[column].values - self.__means[column])/self.__vars[column] \n","          df[column] = final_col_test\n","      \n","      return df\n"],"metadata":{"id":"0NEpy30AuQEc","executionInfo":{"status":"ok","timestamp":1684071788696,"user_tz":-180,"elapsed":1,"user":{"displayName":"Ayşın Tümay","userId":"06380358222498876955"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["class PCA():\n","\n","  \"\"\"\n","  Applies PCA to train and test set.\n","  Draws PVE plot to chose suitable percentage of PC to pick.\n","  \"\"\"\n","  def __init__(self):\n","    self.__eigenvectors = []\n","    self.__pve_list = []\n","    self.__pca = 0\n","    self.__number_of_components = 0\n","  def get_PCA_plot(self, df, threshold):\n","    df = self.__pve_list\n","    self.__number_of_components = [x+1 for x in range(len(df))]\n","    return self.__number_of_components, self.__pve_list\n","\n","  def get_PVE(self):\n","    for i in range(len(self.__pve_list)):\n","      print(f\"Number of components:{self.__number_of_components[i]} -> PVE:{self.__pve_list[i]}\")\n","    \n","  def preprocess_train(self, X_train, threshold):\n","    \n","    df_meaned = (X_train - np.mean(X_train, axis = 0))\n","    cov_matrix = np.cov(df_meaned, rowvar = False)\n","    values, vectors = np.linalg.eigh(cov_matrix)\n","\n","    sorted_index = np.argsort(values)[::-1]\n","    sorted_eigenvalue = values[sorted_index]\n","    sorted_eigenvectors = vectors[:,sorted_index]\n","\n","    pve = []\n","    for i in range(len(sorted_eigenvalue)):\n","        pve_percen = sum(sorted_eigenvalue[:i+1])*100 / np.sum(sorted_eigenvalue)\n","        pve.append(pve_percen)\n","    \n","    self.__pve_list = pve\n","    threshold_list = [pve.index(i) for i in pve if i >= threshold]\n","    threshold_out = threshold_list[0]\n","\n","    sorted_index = sorted_index[:threshold_out+1]\n","    sorted_eigenvalue = sorted_eigenvalue[:threshold_out+1]\n","    sorted_eigenvectors = sorted_eigenvectors[:,:threshold_out+1]\n","    self.__eigenvectors = sorted_eigenvectors\n","\n","    df_PCA = np.dot(sorted_eigenvectors.transpose(),df_meaned.transpose()).transpose()\n","    df_PCA = pd.DataFrame(data=df_PCA,columns=[f\"principal_componenet {y+1}\" for y in range(df_PCA.shape[1])])  \n","    \n","    return df_PCA\n","  \n","  def preprocess_test(self,X_test,X_train):\n","   \n","    df_meaned = X_test - np.mean(X_train, axis = 0)\n","    df_PCA = np.dot(self.__eigenvectors.transpose(),df_meaned.transpose()).transpose()\n","    df_PCA = pd.DataFrame(data=df_PCA,columns=[f\"principal_componenet {y+1}\" for y in range(df_PCA.shape[1])])  \n","\n","    return df_PCA\n"],"metadata":{"id":"9QjQznK9MHk1","executionInfo":{"status":"ok","timestamp":1684071789621,"user_tz":-180,"elapsed":1,"user":{"displayName":"Ayşın Tümay","userId":"06380358222498876955"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["class Linear_Regression():\n"," \n","  def __init__(self, path):\n","\n","    self.__path = path\n","    self._X_train = pd.DataFrame([])\n","    self._Y_train = pd.DataFrame([])\n","    self._X_test = pd.DataFrame([])\n","    self._Y_test = pd.DataFrame([])\n","    self._X_val = pd.DataFrame([])\n","    self._Y_val = pd.DataFrame([])\n","\n","\n","\n","  def train_test(self, scaler_is = None, pca_is = None):\n","      \"\"\"\n","      ;scaler_is: when True performs Standard Scaler\n","      ;pca_is: when True performs PCA\n","      \"\"\"\n","      df_original = pd.read_csv(self.__path, parse_dates = True, index_col = 0) \n","      trainn = df_original.loc[:\"2017-11-30 23:00:00\"]\n","      val = df_original.loc[\"2017-12-01 00:00:00\":\"2017-12-31 23:00:00\"]\n","      test = df_original.loc[\"2018-01-01 00:00:00\":]\n","      scaler = Scaling()\n","\n","      if scaler_is:\n","        trainn = scaler.fit(trainn, minmax = False)\n","        test = scaler.transform(test, minmax = False)\n","        val = scaler.transform(val, minmax = False)\n","      else: \n","        trainn = scaler.fit(trainn, minmax = True)\n","        test = scaler.transform(test, minmax = True)\n","        val = scaler.transform(val, minmax = True)\n","      \n","\n","\n","      self.__Y_train = pd.DataFrame(trainn.iloc[:, -1])\n","      self.__Y_test = pd.DataFrame(test.iloc[:, -1])\n","      self.__Y_val = pd.DataFrame(val.iloc[:, -1])\n","\n","      self.__X_train = pd.DataFrame(trainn.iloc[:, :-1])\n","      self.__X_test = pd.DataFrame(test.iloc[:, :-1])\n","      self.__X_val = pd.DataFrame(val.iloc[:, :-1])\n","      if pca_is :\n","        pca_comp = PCA()\n","        self.__X_train = pca_comp.preprocess_train(np.array(self.__X_train),95)\n","        self.__X_test = pca_comp.preprocess_test(np.array(self.__X_test), np.array(self.__X_train))\n","        self.__X_val = pca_comp.preprocess_test(np.array(self.__X_val), np.array(self.__X_train))\n","\n","      return self.__Y_train,self.__Y_val, self.__Y_test,self.__X_train,self.__X_val,self.__X_test\n","\n","  def loss_function(self,features):\n","\n","    RSS = 0\n","    error = np.sum((np.sum(self.__Y_train ,1)-np.sum((self.__X_train)*features[:-1]+ features[-1],1))**2)\n","    RSS = error/(2*(self.__X_train).shape[0])\n","    return RSS \n","\n","\n","  def gradient_descent(self, L,h,k,features, lasso = None, ridge = None, elasticnet =None):\n"," \n","    grad = np.zeros(len(features))\n","    for i in range(len(features[:-1])):\n","      if lasso:\n","        if features[i] > 0:\n","          grad[i] = -(2/len(self.__Y_train))*np.sum((np.sum(self.__Y_train,1)-np.sum(self.__X_train*features[:-1]+ features[-1],1))*self.__X_train.iloc[:,i] + h)\n","        else:\n","          grad[i] = -(2/len(self.__Y_train))*np.sum((np.sum(self.__Y_train,1)-np.sum(self.__X_train*features[:-1]+ features[-1],1))*self.__X_train.iloc[:,i] - h)\n","      elif ridge:\n","          grad[i] = -(2/len(self.__Y_train))*np.sum((np.sum(self.__Y_train,1)-np.sum(self.__X_train*features[:-1]+ features[-1],1))*self.__X_train.iloc[:,i] + 2*h*features[i])\n","      elif elasticnet:\n","          if features[i] > 0:\n","            grad[i] = -(2/len(self.__Y_train))*np.sum((np.sum(self.__Y_train,1)-np.sum(self.__X_train*features[:-1]+ features[-1],1))*self.__X_train.iloc[:,i] + h + k*features[i])\n","          else:\n","            grad[i] = -(2/len(self.__Y_train))*np.sum((np.sum(self.__Y_train,1)-np.sum(self.__X_train*features[:-1]+ features[-1],1))*self.__X_train.iloc[:,i] - h + k*features[i])\n","      else:\n","          grad[i] = -(2/len(self.__Y_train))*np.sum((np.sum(self.__Y_train,1)-np.sum(self.__X_train*features[:-1]+ features[-1],1))*(self.__X_train).iloc[:,i])\n","\n","    grad[-1] = -(2/len(self.__Y_train))*np.sum((np.sum(self.__Y_train,1)-np.sum(self.__X_train*features[:-1]+ features[-1],1)))\n","    features -= L*grad\n","    return features\n","\n","  # def gradient_descent(self,L,features):\n","\n","  #   grad = np.zeros(len(features))\n","  #   for i in range(len(features[:-1])):\n","  #     grad[i] = -(2/len(self.__Y_train))*np.sum((np.sum(self.__Y_train,1)-np.sum(self.__X_train*features[:-1]+ features[-1],1))*(self.__X_train).iloc[:,i])\n","\n","  #   grad[-1] = -(2/len(self.__Y_train))*np.sum((np.sum(self.__Y_train,1)-np.sum(self.__X_train*features[:-1]+ features[-1],1)))\n","  #   features -= L*grad\n","  #   return features\n","\n","\n","  def training_testing(self, LR, H, K, epoch):\n","    \"\"\"\n","    trains one model\n","    \"\"\"\n","    xlist = []\n","    ylist = [] \n","    features =  np.ones(self.__X_train.shape[1]+1)/5\n","    for i in range(epoch):\n","        features = Linear_Regression.gradient_descent(self, LR,H,K,features, lasso = False, ridge = False, elasticnet = True)\n","        xlist.append(i)\n","        ylist.append(Linear_Regression.loss_function(self,features)) \n","    y_pred = np.sum(self.__X_test*features[:-1]+ features[-1],1)\n","    y_pred_train = np.sum(self.__X_train*features[:-1]+features[-1],1) \n","    print(\"MSE\", mse(self.__Y_test, y_pred),\"MAE\", mae(self.__Y_test, y_pred),\"R2 score\", r2(self.__Y_test, y_pred))\n","    print(\"Train MSE\", mse(self.__Y_train, y_pred_train),\"MAE\", mae(self.__Y_train, y_pred_train),\"R2 score\", r2(self.__Y_train, y_pred_train))\n","\n","    plt.figure(figsize=(10,10))\n","    plt.subplot(211)   \n","    plt.plot(xlist,ylist)\n","    plt.title(\"Epoch vs Training Loss\")\n","    plt.subplot(212)\n","    plt.plot(self.__Y_test.index, self.__Y_test.values)\n","    plt.plot(y_pred.index, y_pred.values)\n","    plt.title(\"Predictions and Ground Truth Test\")\n","    plt.legend([\"test\",\"pred\"])\n","    return y_pred, y_pred_train\n","\n","  def train_val(self, LR, H, K, epochh):\n","    \n","      \"\"\"\n","      ;LR: learning rate\n","      ;H: L1 penalty\n","      ;K: L2 penalty\n","      ;epochh: epoch number\n","      validation function \n","      \"\"\"\n","\n","      xlist = []\n","      ylist = []\n","      features =  np.ones(self.__X_train.shape[1]+1)/5\n","      for i in range(epochh):\n","          features = Linear_Regression.gradient_descent(self, LR,H,K, features, lasso = False, ridge = True, elasticnet = False)\n","          xlist.append(i)\n","          ylist.append(Linear_Regression.loss_function(self,features)) \n","      y_pred = np.sum(self.__X_val*features[:-1]+ features[-1],1)\n","      plt.plot(xlist,ylist)\n","      plt.title(\"Epoch vs Training Loss\")\n","     \n","      return  y_pred\n","\n","  def search(self, parameters):\n","    \"\"\"\n","    takes 1 hour with 15 paramaters.\n","    parameter search for learning rate, lambdas, and epoch\n","    \"\"\"\n","    param_values = [v for v in parameters.values()] \n","    error_of_choice= []\n","    whole_turns = []\n","    for lr,h,k, epoch in itertools.product(*param_values):\n","        y_pred_val = Linear_Regression.train_val(self, lr, h,k, epoch)\n","        MSE = mse(self.__Y_val,y_pred_val)\n","        error_of_choice.append(MSE)\n","        whole_turns.append([lr,epoch,h]) \n","        print('learning rate: %.4f, epoch: %.4f, lambda: %.4f, MSE:%.3f' % (lr,epoch,h,MSE))\n","    min_error_index =error_of_choice.index(min(error_of_choice))\n","    choice = whole_turns[min_error_index]\n","    print('Best parametres','learning rate:',choice[0],'epoch:',choice[1],'lambda:',choice[2], 'MSE:',min(error_of_choice)) \n","\n","    return choice"],"metadata":{"id":"0RQT6iLx0h8M","executionInfo":{"status":"ok","timestamp":1684071789979,"user_tz":-180,"elapsed":3,"user":{"displayName":"Ayşın Tümay","userId":"06380358222498876955"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"tZx05P2dfhbx"},"execution_count":null,"outputs":[]}]}